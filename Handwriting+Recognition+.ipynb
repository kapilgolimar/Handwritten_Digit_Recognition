{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%inline` not found.\n"
     ]
    }
   ],
   "source": [
    "#importing library.\n",
    "from keras. datasets import mnist \n",
    "from keras. models import Sequential  \n",
    "from keras. layers import Dense  \n",
    "from keras. layers import Dropout  \n",
    "from keras. layers import Flatten  \n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras. layers . convolutional import Conv2D  \n",
    "from keras. layers . convolutional import MaxPooling2D  \n",
    "from keras. utils import np_utils \n",
    "from keras import backend as K \n",
    "K . set_image_dim_ordering ( 'th' )\n",
    "\n",
    "import cv2\n",
    "import matplotlib. pyplot as plt \n",
    "% inline matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divided the data into subsets of training and testing.\n",
    "( X_train , y_train ) , ( X_test , y_test ) = mnist. load_data ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since we are working in gray scale we need to set the depth to the value 1.\n",
    "\n",
    "X_train = X_train . reshape ( X_train . shape [ 0 ] , 1 , 28 , 28 ) . astype ( 'float32' )\n",
    "X_test = X_test . reshape ( X_test . shape [ 0 ] , 1 , 28 , 28 ) . astype ( 'float32' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We normalize our data according to the\n",
    "# gray scale. The floating point values ​​are in the range [0,1], instead of [.255]\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts y_train and y_test, which are class vectors, to a binary class array (one-hot vectors)\n",
    "y_train = np_utils. to_categorical ( y_train )\n",
    "y_test = np_utils. to_categorical ( y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of digit types found in MNIST. In this case, the value is 10, corresponding to (0,1,2,3,4,5,6,7,8,9).\n",
    "num_classes = y_test. shape [ 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a CNN model. \n",
    "model = Sequential ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolution2D will be our input layer and it has 30 feature maps with size of 5 × 5.\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The MaxPooling2D layer will be our second layer where we will have a sample window of size 2 x 2.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A new convolutional layer, with 15 feature maps of size 3 × 3, and activation function ReLU.\n",
    "model.add(Conv2D(15, (3, 3), input_shape=(1, 28, 28), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A new subsampling with a 2x2 dimension pooling.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2)) #droppin out .22 % prob.\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 24, 24)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 10, 10)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               48128     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "predict (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 63,639\n",
      "Trainable params: 63,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating three layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax', name='predict'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 264s 4ms/step - loss: 0.4495 - acc: 0.8513 - val_loss: 0.0886 - val_acc: 0.9721\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 268s 4ms/step - loss: 0.1028 - acc: 0.9685 - val_loss: 0.0561 - val_acc: 0.9824\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0729 - acc: 0.9778 - val_loss: 0.0402 - val_acc: 0.9873\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 258s 4ms/step - loss: 0.0600 - acc: 0.9815 - val_loss: 0.0361 - val_acc: 0.9874\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 256s 4ms/step - loss: 0.0517 - acc: 0.9840 - val_loss: 0.0319 - val_acc: 0.9900\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 252s 4ms/step - loss: 0.0448 - acc: 0.9860 - val_loss: 0.0302 - val_acc: 0.9910\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 251s 4ms/step - loss: 0.0392 - acc: 0.9874 - val_loss: 0.0287 - val_acc: 0.9906\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 253s 4ms/step - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0287 - val_acc: 0.9899\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 254s 4ms/step - loss: 0.0333 - acc: 0.9894 - val_loss: 0.0255 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 40136s 669ms/step - loss: 0.0306 - acc: 0.9898 - val_loss: 0.0276 - val_acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x33d054dba8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 99.07%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\nacc: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
